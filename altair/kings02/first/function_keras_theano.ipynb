{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=gpu'\n",
    "##os.environ['THEANO_FLAGS'] = 'floatX=float32,device=gpu,optimizer=fast_compile'\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin/\"\n",
    "\n",
    "#del os.environ[\"THEANO_FLAGS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "from theano import tensor as T\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, RepeatVector\n",
    "from keras.layers import LSTM, GRU, Input, Merge, Reshape, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UNK token will be second to last dimension\n",
    "# EOS token will always be the last dimension\n",
    "# If desired_length is not specified, desired_length will be len(document)\n",
    "# If len(document) < desired_length, add an EOS token an pad with zero vectors to reach desired_length\n",
    "# If len(document) > desired_length, truncate to desired_length\n",
    "def encode_document(document, desired_length=-1, min_unicode_idx=0, max_unicode_idx=128):\n",
    "    UNK_IDX = max_unicode_idx\n",
    "    EOS_IDX = max_unicode_idx + 1\n",
    "    if desired_length == -1:\n",
    "        desired_length = len(document)\n",
    "    encoded = np.zeros((desired_length, max_unicode_idx-min_unicode_idx+2)) # +2 for UNK and EOS tokens\n",
    "    for doc_idx, char in enumerate(document[:desired_length]):\n",
    "        char_encoding = ord(char)\n",
    "        if not min_unicode_idx <= char_encoding < max_unicode_idx:\n",
    "            char_encoding = UNK_IDX\n",
    "        encoded[doc_idx, char_encoding-min_unicode_idx] = 1\n",
    "    if len(document) < desired_length:\n",
    "        encoded[len(document[:desired_length]):, EOS_IDX-min_unicode_idx] = 1\n",
    "    #encoded[len(document[:desired_length]), EOS_IDX-min_unicode_idx] = 1\n",
    "    return encoded.reshape(encoded.shape[0], 1, encoded.shape[1])\n",
    "\n",
    "# By default, desired_length will be the length of the longest document in documents.\n",
    "def encode_documents(documents, desired_length=-1, min_unicode_idx=0, max_unicode_idx=128):\n",
    "    if desired_length == -1:\n",
    "        desired_length = max([len(document) for document in documents])\n",
    "    encodeds = []\n",
    "    for document in documents:\n",
    "        encodeds.append(encode_document(document, desired_length, min_unicode_idx, max_unicode_idx))\n",
    "    e = np.array(encodeds)\n",
    "    return e\n",
    "\n",
    "# encoded must be one-hot, encoded via encode_document()\n",
    "def decode_document(encoded, min_unicode_idx=0, max_unicode_idx=128, unk_decode_idx=32):\n",
    "    UNK_IDX = max_unicode_idx\n",
    "    EOS_IDX = max_unicode_idx + 1\n",
    "    decoded = \"\"\n",
    "    for idx in np.nonzero(encoded)[1]:\n",
    "        candidate = idx + min_unicode_idx\n",
    "        if candidate == UNK_IDX:\n",
    "            candidate = unk_decode_idx\n",
    "        elif candidate == EOS_IDX:\n",
    "            continue\n",
    "        decoded += chr(candidate)\n",
    "    return decoded\n",
    "\n",
    "def decode_documents(encodeds, min_unicode_idx=0, max_unicode_idx=128):\n",
    "    decodeds = []\n",
    "    for encoded in encodeds:\n",
    "        decodeds.append(decode_document(encoded, min_unicode_idx, max_unicode_idx))\n",
    "    return decodeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_conversion(predictions):\n",
    "    converted = np.zeros(predictions.shape)\n",
    "    for prediction_idx, prediction in enumerate(predictions):\n",
    "        for elem_idx, elem in enumerate(prediction):\n",
    "            converted[prediction_idx, elem_idx, np.argmax(elem)] = 1\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from redbaron import RedBaron\n",
    "\n",
    "with open(\"sample.py\", \"r\") as f:\n",
    "    source = f.read()\n",
    "with open(\"sample.py\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "red = RedBaron(source)\n",
    "data = []\n",
    "for fn_node in red.findAll(\"DefNode\"):\n",
    "    starting_line = fn_node.absolute_bounding_box.top_left.to_tuple()[0]\n",
    "    ending_line = fn_node.absolute_bounding_box.bottom_right.to_tuple()[0]\n",
    "    fn_lines = lines[starting_line-1:ending_line-1]\n",
    "    data.append(\"\".join(fn_lines).rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#raw = [\"This is a test.\", \"This is a test2\", \"This is a test3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = data\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimIn = 130\n",
    "dim = 260\n",
    "num_epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = encode_documents(raw)\n",
    "X = e.reshape(e.shape[0], e.shape[1], e.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create and fit the model\n",
    "x0 = Input(shape=X[0].shape)\n",
    "#print(x0.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fork_and_gru(input_layer, activation='relu', return_sequences=False):\n",
    "    fork = Dense(dim, activation='linear')(input_layer)\n",
    "    gru = GRU(dim, activation=activation, return_sequences=return_sequences)(fork)\n",
    "    return fork, gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fork1, gru1 = fork_and_gru(x0, return_sequences=True)\n",
    "fork2, gru2 = fork_and_gru(gru1, return_sequences=True)\n",
    "fork3, gru3 = fork_and_gru(gru2, return_sequences=False)\n",
    "\n",
    "#fork3, gru3 = fork_and_gru(x0, return_sequences=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x3 = Dense(dimIn, activation='linear')(gru3)\n",
    "#print(x3.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x3b = Reshape((1, dimIn))(x3)\n",
    "#print(x3b.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shift_by_one(t1, t2):\n",
    "    t3 = T.concatenate([t1, t2], axis=1) #tf.concat(values=[t1, t2], concat_dim=1)\n",
    "    return t3[:, :-1, :]\n",
    "x4 = Lambda(shift_by_one, output_shape=(X[0].shape), arguments={\"t2\": x0})(x3b)\n",
    "#print(x4.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x5 = Dense(dimIn, activation='linear')(x4)\n",
    "#print(x5.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x6 = GRU(dimIn, activation='relu', return_sequences=True)(x5)\n",
    "#print(x6.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x7 = Activation(\"softmax\")(x6)\n",
    "#print(x7.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(input=x0, output=x7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(clipnorm=5)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"loss\", patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(monitor=\"loss\", filepath=\"weights.{epoch:02d}-{loss:.2f}.hdf5\", save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    if cur_epoch >= num_epochs:\n",
    "        break\n",
    "    model.fit(X, X, batch_size=len(X), nb_epoch=1, verbose=2, shuffle=False, callbacks=[reduce_lr, early_stopping, model_checkpoint])\n",
    "    print(\"Current epoch: %s\" % cur_epoch)\n",
    "    cur_epoch += 1\n",
    "    if cur_epoch % 100 == 0:\n",
    "        print(decode_documents(one_hot_conversion(model.predict(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize performance of the model\n",
    "scores = model.evaluate(X, X, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode_documents(one_hot_conversion(model.predict(X)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Altair",
   "language": "python",
   "name": "altair"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
